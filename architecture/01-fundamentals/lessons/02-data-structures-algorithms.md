# 数据结构与算法基础

## 1. 核心数据结构

数据结构是程序的骨架。选择合适的数据结构，往往比优化算法本身更能提升系统性能。本章将深入讲解五种核心数据结构，并结合实际架构场景分析其选型依据。

### 1.1 数组（Array）

数组是最基础的数据结构，它在内存中占据一段连续的空间，通过下标（索引）直接访问元素。

**内存布局：**

```
地址:  0x100  0x104  0x108  0x10C  0x110
值:    [  10  ][  20  ][  30  ][  40  ][  50  ]
索引:     0       1       2       3       4
```

**操作复杂度：**

| 操作 | 时间复杂度 | 说明 |
|------|-----------|------|
| 随机访问 | O(1) | 通过 base_addr + index * element_size 直接计算地址 |
| 尾部插入 | O(1) 均摊 | 动态数组扩容时需要复制，均摊仍为 O(1) |
| 中间插入 | O(n) | 需要移动后续所有元素 |
| 中间删除 | O(n) | 需要移动后续所有元素 |
| 查找（无序） | O(n) | 线性扫描 |
| 查找（有序） | O(log n) | 二分查找 |

**动态数组的扩容机制：**

以 Java 的 ArrayList 为例，当数组容量不足时，会创建一个新的更大的数组（通常是原来的 1.5 倍），然后将旧数组的元素复制到新数组中。

```java
// ArrayList 扩容核心逻辑（简化版）
private void grow(int minCapacity) {
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1); // 1.5 倍
    elementData = Arrays.copyOf(elementData, newCapacity);
}
```

Go 的 slice 扩容策略更为复杂：当容量小于 256 时翻倍，超过 256 后按约 1.25 倍增长，并进行内存对齐。

**CPU 缓存友好性：**

数组由于内存连续，对 CPU 缓存非常友好。当访问数组的一个元素时，CPU 会将该元素所在的整个缓存行（通常 64 字节）加载到 L1 缓存中，后续访问相邻元素时可以直接命中缓存，避免了访问主存的延迟。这就是为什么在遍历场景下，数组的实际性能远优于链表。

### 1.2 链表（Linked List）

链表由一系列节点组成，每个节点包含数据和指向下一个节点的指针。链表不要求内存连续。

**单链表结构：**

```
[data|next] → [data|next] → [data|next] → null
```

**双向链表结构：**

```
null ← [prev|data|next] ⇄ [prev|data|next] ⇄ [prev|data|next] → null
```

**操作复杂度：**

| 操作 | 时间复杂度 | 说明 |
|------|-----------|------|
| 头部插入/删除 | O(1) | 修改指针即可 |
| 尾部插入/删除 | O(1)（双向链表有尾指针） | 单链表需 O(n) |
| 中间插入/删除 | O(1)（已知位置） | 找到位置后只需修改指针 |
| 随机访问 | O(n) | 必须从头遍历 |
| 查找 | O(n) | 线性扫描 |

**链表的实际应用：**

- **LRU 缓存**：使用双向链表 + 哈希表实现 O(1) 的访问和淘汰
- **操作系统进程调度队列**：使用链表管理就绪队列
- **Java LinkedHashMap**：哈希表 + 双向链表，维护插入顺序

```python
# LRU 缓存的核心思想
class LRUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = OrderedDict()

    def get(self, key):
        if key in self.cache:
            self.cache.move_to_end(key)  # 移到末尾（最近使用）
            return self.cache[key]
        return -1

    def put(self, key, value):
        if key in self.cache:
            self.cache.move_to_end(key)
        self.cache[key] = value
        if len(self.cache) > self.capacity:
            self.cache.popitem(last=False)  # 淘汰最久未使用的
```

### 1.3 哈希表（Hash Table）

哈希表通过哈希函数将键映射到数组的某个位置，实现近似 O(1) 的查找、插入和删除。

**哈希表的核心组成：**
1. **哈希函数**：将任意键映射为数组下标
2. **数组**：存储键值对的底层容器
3. **冲突解决策略**：处理不同键映射到同一位置的情况

**哈希冲突解决方法：**

**方法一：链地址法（Separate Chaining）**

每个数组位置维护一个链表（或红黑树），冲突的元素追加到链表中。

```
数组索引:  [0]  [1]  [2]  [3]  [4]
            │    │    │    │    │
           null  A→D  B   null  C→E→F
```

Java 的 HashMap 采用此方法。当链表长度超过 8 且数组长度超过 64 时，链表会转化为红黑树，将查找复杂度从 O(n) 降为 O(log n)。

**方法二：开放地址法（Open Addressing）**

当发生冲突时，按照某种探测序列在数组中寻找下一个空位。

- 线性探测：依次检查下一个位置（h+1, h+2, h+3...）
- 二次探测：按二次方步长检查（h+1², h+2², h+3²...）
- 双重哈希：使用第二个哈希函数计算步长

Go 的 map 使用的是开放地址法的变体。Python 的 dict 也使用开放地址法。

**负载因子与扩容：**

负载因子 = 已存储元素数 / 数组容量

当负载因子超过阈值时，需要进行扩容（rehash）：
- Java HashMap：阈值 0.75，扩容为 2 倍
- Go map：阈值 6.5（每个桶平均 6.5 个元素），扩容为 2 倍
- Python dict：阈值 2/3，扩容为当前容量的 2-4 倍

**哈希表在分布式系统中的应用——一致性哈希：**

在分布式缓存（如 Memcached、Redis Cluster）中，一致性哈希用于将数据分配到不同的节点。当节点增减时，只需要重新映射少量数据，而不是全部数据。

```
哈希环（0 ~ 2^32-1）：

        Node A
       /      \
      /        \
   Node D    Node B
      \        /
       \      /
        Node C

数据 key 经过哈希后落在环上，顺时针找到的第一个节点即为其归属节点。
```

### 1.4 树（Tree）

树是一种层次化的数据结构，由节点和边组成，每个节点最多有一个父节点。

**二叉搜索树（BST）：**

对于每个节点，左子树所有节点的值小于该节点，右子树所有节点的值大于该节点。

```
        8
       / \
      3   10
     / \    \
    1   6    14
       / \   /
      4   7 13
```

BST 的查找、插入、删除操作的平均时间复杂度为 O(log n)，但在最坏情况下（退化为链表）为 O(n)。

**平衡二叉树（AVL 树）：**

通过旋转操作保证任意节点的左右子树高度差不超过 1，确保所有操作的时间复杂度为 O(log n)。

**红黑树（Red-Black Tree）：**

一种近似平衡的二叉搜索树，通过颜色标记和旋转操作保证最长路径不超过最短路径的 2 倍。

红黑树的五个性质：
1. 每个节点是红色或黑色
2. 根节点是黑色
3. 叶子节点（NIL）是黑色
4. 红色节点的子节点必须是黑色
5. 从任一节点到其所有叶子节点的路径上，黑色节点数量相同

红黑树的应用：Java TreeMap、Linux 内核的进程调度（CFS）、epoll 的文件描述符管理。

**B 树与 B+ 树：**

B 树和 B+ 树是多路平衡搜索树，专为磁盘存储优化设计。

**B 树特点：**
- 每个节点可以有多个子节点（阶为 m 的 B 树，每个节点最多 m 个子节点）
- 所有叶子节点在同一层
- 数据存储在所有节点中

**B+ 树特点（相比 B 树的改进）：**
- 数据只存储在叶子节点
- 叶子节点之间通过指针相连，形成有序链表
- 非叶子节点只存储索引键

```
B+ 树结构示意：

         [  30  |  60  ]          ← 非叶子节点（只存索引）
        /       |       \
  [10|20]    [30|40|50]  [60|70|80]  ← 叶子节点（存数据）
     ↔           ↔           ↔       ← 叶子节点双向链表
```

### 1.5 图（Graph）

图由顶点（Vertex）和边（Edge）组成，用于表示实体之间的关系。

**图的存储方式：**

**邻接矩阵：**
```
    A  B  C  D
A [ 0  1  1  0 ]
B [ 1  0  0  1 ]
C [ 1  0  0  1 ]
D [ 0  1  1  0 ]
```
- 空间复杂度：O(V²)
- 查询两点是否相连：O(1)
- 适合稠密图

**邻接表：**
```
A → [B, C]
B → [A, D]
C → [A, D]
D → [B, C]
```
- 空间复杂度：O(V + E)
- 查询两点是否相连：O(degree)
- 适合稀疏图

**图的遍历算法：**

- **BFS（广度优先搜索）**：使用队列，逐层遍历。适合求最短路径（无权图）。
- **DFS（深度优先搜索）**：使用栈（或递归），沿一条路径深入到底再回溯。适合拓扑排序、连通分量检测。

**图在架构中的应用：**
- 微服务依赖关系分析（拓扑排序检测循环依赖）
- 社交网络关系建模
- 网络路由算法（Dijkstra、Bellman-Ford）
- 任务调度（DAG，有向无环图）

---

## 2. 时间复杂度与空间复杂度分析

### 2.1 大 O 表示法

大 O 表示法描述的是算法在最坏情况下的增长趋势，忽略常数因子和低阶项。

**常见复杂度排序（从低到高）：**

```
O(1) < O(log n) < O(n) < O(n log n) < O(n²) < O(2^n) < O(n!)
```

**直观理解（n = 1,000,000 时的操作次数）：**

| 复杂度 | 操作次数 | 实际含义 |
|--------|---------|----------|
| O(1) | 1 | 哈希表查找 |
| O(log n) | 20 | 二分查找 |
| O(n) | 1,000,000 | 线性扫描 |
| O(n log n) | 20,000,000 | 归并排序 |
| O(n²) | 1,000,000,000,000 | 冒泡排序（不可接受） |

### 2.2 均摊分析（Amortized Analysis）

某些操作偶尔会很慢，但平均下来每次操作的成本很低。

典型例子：动态数组的 append 操作。大多数时候是 O(1)，但扩容时需要 O(n)。通过均摊分析，每次 append 的均摊复杂度仍为 O(1)。

```
操作序列：append, append, append, append(扩容), append, append, append, append(扩容)
成本：      1,      1,      1,      4+1,        1,      1,      1,      8+1
总成本 = 8 + (4 + 8) = 20
平均成本 = 20 / 8 = 2.5 = O(1)
```

### 2.3 空间复杂度

空间复杂度衡量算法执行过程中额外使用的内存空间。

```python
# O(1) 空间 —— 原地操作
def reverse_array(arr):
    left, right = 0, len(arr) - 1
    while left < right:
        arr[left], arr[right] = arr[right], arr[left]
        left += 1
        right -= 1

# O(n) 空间 —— 需要额外数组
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    return merge(left, right)

# O(n) 空间 —— 递归调用栈
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
```

### 2.4 架构设计中的复杂度思维

在架构设计中，复杂度分析不仅限于单个算法，还需要考虑：

- **接口响应时间**：一个 API 的时间复杂度决定了它在数据量增长时的表现
- **存储成本**：空间复杂度直接影响存储费用
- **扩展性**：O(n²) 的算法在数据量翻倍时，处理时间变为 4 倍

---

## 3. 常用算法思想

### 3.1 分治法（Divide and Conquer）

将问题分解为若干个规模较小的子问题，递归求解子问题，然后合并结果。

**经典应用：归并排序**

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr

    mid = len(arr) // 2
    left = merge_sort(arr[:mid])    # 分解
    right = merge_sort(arr[mid:])   # 分解

    return merge(left, right)        # 合并

def merge(left, right):
    result = []
    i = j = 0
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    result.extend(left[i:])
    result.extend(right[j:])
    return result
```

**分治法在架构中的应用：**
- MapReduce：将大数据集分割到多个节点并行处理，最后合并结果
- 分库分表：将大表按规则拆分到多个数据库实例
- CDN 分发：将内容分发到多个边缘节点

### 3.2 贪心算法（Greedy Algorithm）

每一步都选择当前最优的方案，期望最终得到全局最优解。贪心算法不一定能得到全局最优解，但在某些问题上可以证明其正确性。

**经典应用：Dijkstra 最短路径算法**

```python
import heapq

def dijkstra(graph, start):
    distances = {node: float('inf') for node in graph}
    distances[start] = 0
    pq = [(0, start)]  # (距离, 节点)

    while pq:
        current_dist, current_node = heapq.heappop(pq)

        if current_dist > distances[current_node]:
            continue

        for neighbor, weight in graph[current_node].items():
            distance = current_dist + weight
            if distance < distances[neighbor]:
                distances[neighbor] = distance
                heapq.heappush(pq, (distance, neighbor))

    return distances
```

**贪心算法在架构中的应用：**
- 负载均衡：最少连接数算法（选择当前连接数最少的服务器）
- 任务调度：最短作业优先（SJF）
- 哈夫曼编码：数据压缩

### 3.3 动态规划（Dynamic Programming）

将问题分解为重叠的子问题，通过记录子问题的解来避免重复计算。

**动态规划的两个核心条件：**
1. 最优子结构：问题的最优解包含子问题的最优解
2. 重叠子问题：不同的问题分解路径会产生相同的子问题

**经典应用：背包问题**

```python
def knapsack(weights, values, capacity):
    n = len(weights)
    # dp[i][w] 表示前 i 个物品、容量为 w 时的最大价值
    dp = [[0] * (capacity + 1) for _ in range(n + 1)]

    for i in range(1, n + 1):
        for w in range(capacity + 1):
            dp[i][w] = dp[i-1][w]  # 不选第 i 个物品
            if w >= weights[i-1]:
                dp[i][w] = max(dp[i][w],
                              dp[i-1][w - weights[i-1]] + values[i-1])

    return dp[n][capacity]
```

**动态规划在架构中的应用：**
- 资源分配优化：在有限预算下最大化系统性能
- 路由优化：网络中的最优路径选择
- 缓存策略：最优缓存替换策略的理论基础

---

## 4. 架构设计中的数据结构选型

### 4.1 为什么 Redis 使用跳表（Skip List）而不是红黑树？

Redis 的有序集合（Sorted Set）底层使用跳表实现。这是一个经典的数据结构选型案例。

**跳表的结构：**

```
Level 3:  HEAD ──────────────────────────────→ 50 ──────────────→ NIL
Level 2:  HEAD ──────────→ 20 ──────────────→ 50 ──→ 70 ──────→ NIL
Level 1:  HEAD ──→ 10 ──→ 20 ──→ 30 ──→ 40 → 50 ──→ 70 ──→ 90 → NIL
```

跳表是在有序链表的基础上增加多级索引，通过"跳跃"来加速查找，平均时间复杂度为 O(log n)。

**Redis 选择跳表的原因：**

1. **实现简单**：跳表的代码量远少于红黑树，更容易理解和维护。Redis 的作者 antirez 明确表示过这一点。

2. **范围查询高效**：跳表的底层是有序链表，范围查询（ZRANGEBYSCORE）只需找到起始位置后顺序遍历即可。红黑树的范围查询需要中序遍历，实现更复杂。

3. **并发友好**：跳表可以通过细粒度锁或无锁算法实现并发安全（如 Java 的 ConcurrentSkipListMap）。红黑树的旋转操作涉及多个节点的修改，并发控制更困难。

4. **内存局部性**：跳表的节点通过指针连接，在实际实现中可以通过内存池优化分配。

### 4.2 为什么 MySQL（InnoDB）使用 B+ 树而不是哈希表或红黑树？

**为什么不用哈希表？**
- 哈希表只支持等值查询（=），不支持范围查询（BETWEEN、>、<）
- 哈希表无法利用索引进行排序（ORDER BY）
- 哈希冲突可能导致性能退化

**为什么不用红黑树？**
- 红黑树是二叉树，树的高度为 O(log₂ n)
- 对于 1000 万条数据，红黑树高度约为 23 层，意味着最多需要 23 次磁盘 I/O
- B+ 树是多路树，每个节点可以存储上千个键，树高通常只有 3-4 层
- 3-4 次磁盘 I/O 远优于 23 次

**B+ 树的优势：**

1. **磁盘 I/O 最优化**：B+ 树的节点大小通常设置为一个磁盘页（16KB），每次 I/O 读取一个完整节点。由于每个节点存储大量键，树的高度极低。

2. **范围查询高效**：叶子节点形成有序链表，范围查询只需定位起始叶子节点后顺序扫描。

3. **查询性能稳定**：所有数据都在叶子节点，每次查询的路径长度相同。

```
InnoDB B+ 树索引示意（假设每页可存 1000 个键）：

根节点（1 页）：可索引 1000 个范围
  ↓
第二层（~1000 页）：可索引 1,000,000 个范围
  ↓
第三层（~1,000,000 页）：可存储 ~10 亿条记录

结论：10 亿条数据，只需 3 次磁盘 I/O 即可定位到目标记录！
```

### 4.3 为什么 Kafka 使用追加写日志（Append-Only Log）？

Kafka 的消息存储使用顺序追加写入的日志文件，而不是传统的数据库结构。

**原因分析：**

1. **磁盘顺序写性能**：顺序写入的速度可以达到 600MB/s 以上，接近内存的随机写入速度。而磁盘随机写入通常只有几 MB/s。

2. **零拷贝（Zero Copy）**：配合 sendfile 系统调用，数据可以直接从磁盘文件传输到网络套接字，无需经过用户空间。

3. **简单高效**：追加写入不需要维护复杂的索引结构，写入路径极短。

4. **天然有序**：消息按写入顺序排列，消费者可以通过 offset 精确定位。

### 4.4 为什么 Go 的 map 不是并发安全的？

Go 的内置 map 不支持并发读写，这是一个有意的设计决策。

**原因：**
1. 大多数使用场景不需要并发访问，加锁会带来不必要的性能开销
2. Go 提供了 sync.Map 用于需要并发安全的场景
3. 遵循"不要为不需要的功能付费"的设计原则

```go
// 并发安全的 map 使用方式
// 方式一：sync.Mutex
var mu sync.Mutex
m := make(map[string]int)

mu.Lock()
m["key"] = 42
mu.Unlock()

// 方式二：sync.Map（适合读多写少的场景）
var sm sync.Map
sm.Store("key", 42)
value, ok := sm.Load("key")

// 方式三：channel（Go 推荐的方式）
// "不要通过共享内存来通信，而要通过通信来共享内存"
```

### 4.5 数据结构选型决策框架

在架构设计中选择数据结构时，应考虑以下因素：

```
                    ┌─ 读多写少？→ 哈希表、B+ 树
                    │
数据访问模式 ──────┼─ 写多读少？→ 追加日志、LSM 树
                    │
                    ├─ 范围查询？→ B+ 树、跳表
                    │
                    └─ 等值查询？→ 哈希表

                    ┌─ 磁盘存储？→ B+ 树、LSM 树
                    │
存储介质 ──────────┼─ 内存存储？→ 哈希表、红黑树、跳表
                    │
                    └─ SSD？→ LSM 树（写放大较小）

                    ┌─ 需要并发？→ 跳表、无锁哈希表
                    │
并发需求 ──────────┼─ 单线程？→ 任意结构均可
                    │
                    └─ 读写比？→ 读写锁 + 对应结构
```

---

## 本章小结

数据结构与算法是架构设计的内功。理解每种数据结构的特性和适用场景，能够帮助架构师在系统设计中做出正确的技术决策。关键要点：

1. 没有"最好"的数据结构，只有"最适合"的数据结构
2. 时间复杂度和空间复杂度是评估方案的基本工具
3. 实际系统中的数据结构选型需要综合考虑访问模式、存储介质、并发需求等多个因素
4. 理解经典系统（Redis、MySQL、Kafka）的数据结构选型理由，有助于培养架构直觉
5. 分治、贪心、动态规划等算法思想在架构设计中有广泛的映射和应用
